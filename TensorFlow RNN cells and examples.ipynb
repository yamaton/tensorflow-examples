{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN layer playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single RNN layer computation using several implementations of TensorFlow's RNN cells are discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2 \n",
    "SEQ_LEN = 3      # steps in time dimension\n",
    "NUM_INPUTS = 4   # number of input elements\n",
    "NUM_UNITS = 5    # number of output elements\n",
    "\n",
    "cell_type = \"gru\"   # \"lstm\" or \"gru\"\n",
    "\n",
    "# [For CPU] Use CUDA compatible cell?\n",
    "cuda_compatible = False\n",
    "\n",
    "# [For CPU] Use faster cell?\n",
    "performance_matters = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the input tensor to RNN layer have the shape (`BATCH_SIZE`, `SEQ_LEN` , `NUM_INPUT`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.4401753 , 0.6901737 , 0.7132639 , 0.4629155 ],\n",
       "        [0.635675  , 0.7819176 , 0.5435599 , 0.8797472 ],\n",
       "        [0.54418594, 0.9816287 , 0.48195803, 0.15588744]],\n",
       "\n",
       "       [[0.603667  , 0.09109777, 0.7939124 , 0.12160426],\n",
       "        [0.3935575 , 0.9057583 , 0.7423673 , 0.62571424],\n",
       "        [0.77721334, 0.8152382 , 0.38591084, 0.25880244]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_inputs = tf.convert_to_tensor(np.float32(np.random.random((BATCH_SIZE, SEQ_LEN, NUM_INPUTS))))\n",
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of RNN cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed [here](https://www.tensorflow.org/performance/performance_guide#rnn_performance), `tf.nn.rnn_cell.*` provides only the reference design not meant for perforance computation. \n",
    "\n",
    "* For GPU performance `tf.contrib.cudnn_rnn.*` is recommended.\n",
    "* For CPU performance `tf.contrib.rnn.*BlockCell*` is recommended.\n",
    "* `tf.nn.rnn_cell.*` provides reference implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[NOTE]** `tf.float64` does not work with `LSTMBlockCell` and `GRUBlockCellV2` as of v1.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    selector = {\n",
    "        \"lstm\":  tf.contrib.cudnn_rnn.CudnnLSTM,\n",
    "        \"gru\":  tf.contrib.cudnn_rnn.CudnnGRU, \n",
    "    }\n",
    "elif cuda_compatible:\n",
    "    selector = {\n",
    "        \"lstm\":  tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell,\n",
    "        \"gru\":  tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell, \n",
    "    }\n",
    "elif performance_matters:\n",
    "    selector = {\n",
    "        \"lstm\": tf.contrib.rnn.LSTMBlockCell,\n",
    "        \"gru\":  tf.contrib.rnn.GRUBlockCellV2,\n",
    "    } \n",
    "else:\n",
    "    selector = {\n",
    "        \"lstm\": tf.nn.rnn_cell.LSTMCell,\n",
    "        \"gru\":  tf.nn.rnn_cell.GRUCell, \n",
    "    }\n",
    "\n",
    "rnn_cell_func = selector[cell_type]\n",
    "rnn_cell = rnn_cell_func(NUM_UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_state(cell_type, batch_size=BATCH_SIZE, num_units=NUM_UNITS, dtype=tf.float32):\n",
    "    assert cell_type in (\"lstm\", \"gru\")\n",
    "    if cell_type == \"lstm\":\n",
    "        LSTMStateTuple = collections.namedtuple(\"LSTMStateTuple\", [\"c\", \"h\"])\n",
    "        left = tf.zeros(shape=(batch_size, num_units), dtype=dtype)\n",
    "        right = tf.zeros(shape=(batch_size, num_units), dtype=dtype)\n",
    "        res = LSTMStateTuple(left, right)\n",
    "    else:\n",
    "        res = tf.zeros(shape=(batch_size, num_units), dtype=dtype)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_initial_state = get_initial_state(cell_type)\n",
    "rnn_initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct implementaiton using the RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "rnn_state = rnn_initial_state\n",
    "for i in range(SEQ_LEN):\n",
    "    output_snapshot, rnn_state = rnn_cell(tf.convert_to_tensor(rnn_inputs[:, i, :]), rnn_state)\n",
    "    stack.append(output_snapshot)\n",
    "tmp = tf.convert_to_tensor(stack)          # time major\n",
    "rnn_output = tf.transpose(tmp, [1, 0, 2])  # batch major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=93, shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[ 0.06355083,  0.10468215, -0.00351658, -0.06466059,\n",
       "         -0.12453991],\n",
       "        [ 0.11457729,  0.2151941 ,  0.07290673,  0.03237692,\n",
       "         -0.21750826],\n",
       "        [ 0.07553838,  0.26621968,  0.15797816, -0.09341604,\n",
       "         -0.3176002 ]],\n",
       "\n",
       "       [[ 0.10963777,  0.0522937 , -0.15269682, -0.00395007,\n",
       "         -0.11811382],\n",
       "        [ 0.13747731,  0.16242859, -0.04078223, -0.09043062,\n",
       "         -0.22412425],\n",
       "        [ 0.11365119,  0.21294627,  0.05266741, -0.07813045,\n",
       "         -0.31754592]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=90, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.07553838,  0.26621968,  0.15797816, -0.09341604, -0.3176002 ],\n",
       "       [ 0.11365119,  0.21294627,  0.05266741, -0.07813045, -0.31754592]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalent code with dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_output2, rnn_state2 = tf.nn.dynamic_rnn(rnn_cell, rnn_inputs, initial_state=rnn_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=188, shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[ 0.06355083,  0.10468215, -0.00351658, -0.06466059,\n",
       "         -0.12453991],\n",
       "        [ 0.11457729,  0.2151941 ,  0.07290673,  0.03237692,\n",
       "         -0.21750826],\n",
       "        [ 0.07553838,  0.26621968,  0.15797816, -0.09341604,\n",
       "         -0.3176002 ]],\n",
       "\n",
       "       [[ 0.10963777,  0.0522937 , -0.15269682, -0.00395007,\n",
       "         -0.11811382],\n",
       "        [ 0.13747731,  0.16242859, -0.04078223, -0.09043062,\n",
       "         -0.22412425],\n",
       "        [ 0.11365119,  0.21294627,  0.05266741, -0.07813045,\n",
       "         -0.31754592]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=176, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.07553838,  0.26621968,  0.15797816, -0.09341604, -0.3176002 ],\n",
       "       [ 0.11365119,  0.21294627,  0.05266741, -0.07813045, -0.31754592]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalence checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results from direct implementation and `dynamic_rnn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rnn_output.numpy() == rnn_output2.numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cell_type == \"lstm\":\n",
    "    res = ((rnn_state.c.numpy() == rnn_state2.c.numpy()).all() \n",
    "           and (rnn_state.h.numpy() == rnn_state2.h.numpy()).all())\n",
    "else:\n",
    "    res = (rnn_state.numpy() == rnn_state2.numpy()).all()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following relation holds unless some sequences are short and zero-padded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cell_type == \"lstm\":\n",
    "    check = (rnn_output[:, -1, :].numpy() == rnn_state.h.numpy()).all()\n",
    "else:\n",
    "    check = (rnn_output[:, -1, :].numpy() == rnn_state.numpy()).all()\n",
    "\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra] LSTMBlockFusedCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.contrib.rnn.LSTMBlockFusedCell` provides yet another fast implementation of LSTM. \n",
    "\n",
    "**NOTE:** `LSTMBlockFusedCell` takes **time-major** tensor, not batch-major."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = tf.contrib.rnn.LSTMBlockFusedCell(NUM_UNITS)\n",
    "rnn_initial_state = get_initial_state(cell_type=\"lstm\")\n",
    "rnn_inputs_time_major = tf.transpose(tf.convert_to_tensor(rnn_inputs), [1, 0, 2])\n",
    "res = rnn_cell(rnn_inputs_time_major, initial_state=rnn_initial_state)\n",
    "rnn_output_time_major, rnn_state = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=242, shape=(3, 2, 5), dtype=float32, numpy=\n",
       "array([[[ 0.12242151,  0.0277885 , -0.0754373 ,  0.11143345,\n",
       "         -0.063211  ],\n",
       "        [ 0.10178996, -0.09440513, -0.0234403 ,  0.12939812,\n",
       "          0.02685089]],\n",
       "\n",
       "       [[ 0.20673898,  0.04889306, -0.09390434,  0.17848039,\n",
       "         -0.14704858],\n",
       "        [ 0.20499304,  0.00816838, -0.09620755,  0.20845538,\n",
       "         -0.076874  ]],\n",
       "\n",
       "       [[ 0.27044514,  0.07677974, -0.11766715,  0.22938018,\n",
       "         -0.16622667],\n",
       "        [ 0.29983306,  0.00716148, -0.0777734 ,  0.23880504,\n",
       "         -0.13313416]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output_time_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor: id=246, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.7442485 ,  0.14714137, -0.24902591,  0.6121015 , -0.38773277],\n",
       "       [ 0.750517  ,  0.01361619, -0.16515471,  0.6710374 , -0.27689147]],\n",
       "      dtype=float32)>, h=<tf.Tensor: id=250, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.27044514,  0.07677974, -0.11766715,  0.22938018, -0.16622667],\n",
       "       [ 0.29983306,  0.00716148, -0.0777734 ,  0.23880504, -0.13313416]],\n",
       "      dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
