{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN layer playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single RNN layer computation using several implementations of TensorFlow's RNN cells are discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2 \n",
    "SEQ_LEN = 3      # steps in time dimension\n",
    "NUM_INPUTS = 4   # number of input elements\n",
    "NUM_UNITS = 5    # number of output elements\n",
    "\n",
    "cell_type = \"gru\"   # \"lstm\" or \"gru\"\n",
    "\n",
    "# [For CPU] Use CUDA compatible cell?\n",
    "cuda_compatible = True\n",
    "\n",
    "# [For CPU] Use faster cell?\n",
    "performance_matters = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the input tensor to RNN layer have the shape (`BATCH_SIZE`, `SEQ_LEN` , `NUM_INPUT`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.01699759, 0.8343653 , 0.26878107, 0.6359202 ],\n",
       "        [0.75250006, 0.53498155, 0.7937529 , 0.8391873 ],\n",
       "        [0.3019563 , 0.27737612, 0.5271342 , 0.45266452]],\n",
       "\n",
       "       [[0.82940054, 0.63020486, 0.9112391 , 0.9472608 ],\n",
       "        [0.28364596, 0.6899779 , 0.80933154, 0.97504157],\n",
       "        [0.72382927, 0.6976915 , 0.25315878, 0.29028106]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_inputs = tf.convert_to_tensor(np.float32(np.random.random((BATCH_SIZE, SEQ_LEN, NUM_INPUTS))))\n",
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of RNN cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed [here](https://www.tensorflow.org/performance/performance_guide#rnn_performance), `tf.nn.rnn_cell.*` provides only the reference design not meant for perforance computation. \n",
    "\n",
    "* For GPU performance `tf.contrib.cudnn_rnn.*` is recommended.\n",
    "* For CPU performance `tf.contrib.rnn.*BlockCell*` is recommended.\n",
    "* `tf.nn.rnn_cell.*` provides reference implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[NOTE]** `tf.float64` does not work with `LSTMBlockCell` and `GRUBlockCellV2` as of v1.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda_compatible:\n",
    "    selector = {\n",
    "        \"lstm\":  tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell,\n",
    "        \"gru\":  tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell, \n",
    "    }\n",
    "elif performance_matters:\n",
    "    selector = {\n",
    "        \"lstm\": tf.contrib.rnn.LSTMBlockCell,\n",
    "        \"gru\":  tf.contrib.rnn.GRUBlockCellV2,\n",
    "    } \n",
    "else:\n",
    "    selector = {\n",
    "        \"lstm\": tf.nn.rnn_cell.LSTMCell,\n",
    "        \"gru\":  tf.nn.rnn_cell.GRUCell, \n",
    "    }\n",
    "\n",
    "rnn_cell_func = selector[cell_type]\n",
    "rnn_cell = rnn_cell_func(NUM_UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_state(cell_type, batch_size=BATCH_SIZE, num_units=NUM_UNITS, dtype=tf.float32):\n",
    "    assert cell_type in (\"lstm\", \"gru\")\n",
    "    if cell_type == \"lstm\":\n",
    "        LSTMStateTuple = collections.namedtuple(\"LSTMStateTuple\", [\"c\", \"h\"])\n",
    "        left = tf.zeros(shape=(batch_size, num_units), dtype=dtype)\n",
    "        right = tf.zeros(shape=(batch_size, num_units), dtype=dtype)\n",
    "        res = LSTMStateTuple(left, right)\n",
    "    else:\n",
    "        res = tf.zeros(shape=(batch_size, num_units), dtype=dtype)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_initial_state = get_initial_state(cell_type)\n",
    "rnn_initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct implementaiton using the RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell: cudnn_compatible_gru_cell_1\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN cell:\", rnn_cell.name)\n",
    "stack = []\n",
    "rnn_state = rnn_initial_state\n",
    "for i in range(SEQ_LEN):\n",
    "    output_snapshot, rnn_state = rnn_cell(rnn_inputs[:, i, :], rnn_state)\n",
    "    stack.append(output_snapshot)\n",
    "tmp = tf.convert_to_tensor(stack)          # time major\n",
    "rnn_output = tf.transpose(tmp, [1, 0, 2])  # batch major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=168, shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[ 0.02990399,  0.05910603, -0.05918583, -0.1534747 ,\n",
       "          0.15635811],\n",
       "        [ 0.12331079,  0.20804977,  0.06027195, -0.3613307 ,\n",
       "          0.23384589],\n",
       "        [ 0.15892234,  0.24210683,  0.17441162, -0.30702627,\n",
       "          0.27366194]],\n",
       "\n",
       "       [[ 0.10151232,  0.18144394,  0.08772551, -0.32502905,\n",
       "          0.12613314],\n",
       "        [ 0.16009198,  0.2600469 ,  0.16925618, -0.4235642 ,\n",
       "          0.2972222 ],\n",
       "        [ 0.16468492,  0.29950017,  0.2038032 , -0.28208566,\n",
       "          0.32650927]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=165, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.15892234,  0.24210683,  0.17441162, -0.30702627,  0.27366194],\n",
       "       [ 0.16468492,  0.29950017,  0.2038032 , -0.28208566,  0.32650927]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalent code with dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell: cudnn_compatible_gru_cell_1\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN cell:\", rnn_cell.name)\n",
    "rnn_output2, rnn_state2 = tf.nn.dynamic_rnn(rnn_cell, rnn_inputs, initial_state=rnn_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=556, shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[ 0.02990399,  0.05910603, -0.05918583, -0.1534747 ,\n",
       "          0.15635811],\n",
       "        [ 0.12331079,  0.20804977,  0.06027195, -0.3613307 ,\n",
       "          0.23384589],\n",
       "        [ 0.15892234,  0.24210683,  0.17441162, -0.30702627,\n",
       "          0.27366194]],\n",
       "\n",
       "       [[ 0.10151232,  0.18144394,  0.08772551, -0.32502905,\n",
       "          0.12613314],\n",
       "        [ 0.16009198,  0.2600469 ,  0.16925618, -0.4235642 ,\n",
       "          0.2972222 ],\n",
       "        [ 0.16468492,  0.29950017,  0.2038032 , -0.28208566,\n",
       "          0.32650927]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=544, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.15892234,  0.24210683,  0.17441162, -0.30702627,  0.27366194],\n",
       "       [ 0.16468492,  0.29950017,  0.2038032 , -0.28208566,  0.32650927]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalence checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results from direct implementation and `dynamic_rnn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rnn_output.numpy() == rnn_output2.numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cell_type == \"lstm\":\n",
    "    res = ((rnn_state.c.numpy() == rnn_state2.c.numpy()).all() \n",
    "           and (rnn_state.h.numpy() == rnn_state2.h.numpy()).all())\n",
    "else:\n",
    "    res = (rnn_state.numpy() == rnn_state2.numpy()).all()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following relation holds unless some sequences are short and zero-padded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cell_type == \"lstm\":\n",
    "    check = (rnn_output[:, -1, :].numpy() == rnn_state.h.numpy()).all()\n",
    "else:\n",
    "    check = (rnn_output[:, -1, :].numpy() == rnn_state.numpy()).all()\n",
    "\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN whole-sequence processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CudnnGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN implementation: cudnn_gru_4\n"
     ]
    }
   ],
   "source": [
    "rnn_block = tf.contrib.cudnn_rnn.CudnnGRU(1, NUM_UNITS)\n",
    "\n",
    "print(\"RNN implementation:\", rnn_block.name)\n",
    "# rnn_inputs_time_major = tf.transpose(tf.convert_to_tensor(rnn_inputs), [1, 0, 2])\n",
    "rnn_inputs_time_major = tf.transpose(rnn_inputs, [1, 0, 2])\n",
    "if tf.test.gpu_device_name():\n",
    "    res = rnn_block(rnn_inputs_time_major)\n",
    "    rnn_output_time_major, rnn_state = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 5],)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_block.state_shape(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gru'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_block.rnn_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra] LSTMBlockFusedCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.contrib.rnn.LSTMBlockFusedCell` provides yet another fast implementation of LSTM. \n",
    "\n",
    "**NOTE:** `LSTMBlockFusedCell` takes **time-major** tensor, not batch-major."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN implementation: lstm_fused_cell\n"
     ]
    }
   ],
   "source": [
    "rnn_block = tf.contrib.rnn.LSTMBlockFusedCell(NUM_UNITS)\n",
    "print(\"RNN implementation:\", rnn_block.name)\n",
    "\n",
    "rnn_initial_state = get_initial_state(cell_type=\"lstm\")\n",
    "rnn_inputs_time_major = tf.transpose(rnn_inputs, [1, 0, 2])\n",
    "res = rnn_block(rnn_inputs_time_major, initial_state=rnn_initial_state)\n",
    "rnn_output_time_major, rnn_state = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_output_time_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
